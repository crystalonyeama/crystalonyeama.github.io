---
layout: post
title: "Day 31 – XGBoost Exploration and Dataset Preparation"
date: 2025-07-08
author: Crystal Onyeama
permalink: /day31.html
tags: ["XGBoost", "data preprocessing", "dataset integration", "model selection"]

what_i_learned: |
  I began the day by reviewing the task slides to clearly map out what I needed to focus on. One of the key goals today was understanding XGBoost, the new machine learning model we plan to use for our project. I spent time researching how it works, its strengths, and why it could be a good fit for our dataset—particularly in helping us make accurate predictions based on complex structured data. It was important to me to not just use the model, but really understand its role in our pipeline.

  After that, I uploaded the large dataset I found yesterday into our shared Google Drive so my team could access it. The folder was huge, so the upload process took quite a bit of time. Once it was done, our group shifted into planning how we’ll clean and preprocess this new data, ensuring it aligns with the structure of our existing datasets.

  In the afternoon, we began hands-on coding by focusing on cleaning the Hospital Italiano dataset. This dataset contains the most detailed and consistent labeling, which makes it ideal for preparing our features for XGBoost training. We’re now working on getting the format just right so we can include it in the merged dataset and begin training.

blockers: |
  Uploading the large dataset was time-consuming and slowed down the start of our coding session. Additionally, mapping out the best way to preprocess the new data without losing important information required extra discussion.

reflection: |
  Today was all about preparation and deeper understanding. Learning about XGBoost gave me more confidence moving forward with this next stage of the project. Even though data handling can be time-consuming, I know it’s one of the most critical steps—and I’m glad we’re being thorough before jumping into training.
---
